---
title: "Echantillonnage préférentiel"
author: "Pierre Gloaguen"
date: ""
toc: yes
toc_float: yes
output:
  pdf_document: 
    number_sections: yes
    includes:
      in_header: style_correction.tex
  html_document:
    theme: journal
    highlight: tango
    number_sections: yes
subtitle: Travaux dirigés
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, comment = NA,
                      cache = TRUE)
```

# Évènement rare

On veut estimer la probabilité $p^*$ qu'une loi normale centrée réduite dépasse la valeur 3.
 
 1. Pour un effort de Monte Carlo de taille $M$, proposer un estimateur de Monte Carlo pour $p^*$.
 
\begin{Correction}

On peut poser $$\hat{p} = \frac{1}{M}\sum_{k = 1}^M \mathbf{1}_{X_k > 3}$$
 où les $X_1,\dots X_M$ sont des variables aléatoires i.i.d. de loi normale $\mathcal{N}(0, 1)$.

\end{Correction}
 
 2. Implémenter cet estimateur sur `R` pour un effort de Monte Carlo de taille $M= 10000$

```{r library, message = FALSE}
library(tidyverse)
```

\begin{Correction}

La fonction suit le même squelette que d'habitude

\end{Correction}

```{r get_mc_estimate_exo1}
get_monte_carlo_estimate <- function(M, threshold = 3){
  x_sample <- rnorm(M, 0, 1) # Simulation des X
  above_threshold <-  x_sample > threshold
  z_975 <- qnorm(0.975) # Quantile de la loi normale
  p_hat <- cumsum(above_threshold) / (1:M) # Estimation de p
  # Fast way to compute E[f(x)^2] - E[f(x)]^2 on the fly
  sigma2_p_hat <- cumsum(above_threshold^2) / (1:M) - p_hat^2
  # Sotcking in a data_frame
  tibble(index = 1:M,
         phi_x = above_threshold,
         p_hat = p_hat) %>% 
    mutate(sup_IC_emp = p_hat + z_975 * sqrt(sigma2_p_hat / index), # IC bounds
           inf_IC_emp = p_hat - z_975 * sqrt(sigma2_p_hat / index))
}
```


```{r implem_mc_gaussien, cache = T}
set.seed(123) # For reproductible results
my_monte_carlo_estimate <- get_monte_carlo_estimate(1e4)
```

```{r graphe_mc_gaussien}
my_monte_carlo_estimate %>%
  ggplot(aes(x = index, y = p_hat)) +
    geom_ribbon(mapping = aes(ymin = inf_IC_emp, ymax = sup_IC_emp), 
                fill = "lightblue", alpha = 0.5) +
  coord_cartesian(y = c(0, 0.01)) + # Zoom on the interesting zone
  geom_point() +
  labs(x = "Effort Monte Carlo",  y = expression(hat(p)),
       title = "Estimation par Monte Carlo") +
  geom_hline(yintercept = 1 - pnorm(3), # True value
             linetype = 2, col = "red")
``` 

\begin{Correction}

On peut constater que l'estimation est très instable, avec un IC asymptotique qui comprend très longtemps des valeurs négatives!
La variance empirique de l'estimateur peut être obtenue:

\end{Correction}

```{r variance_empirique_monte_carlo_exo1}
var(my_monte_carlo_estimate$phi_x)
```

 
3. On se propose d'utiliser un échantillonnage préférentiel pour estimer cette probabilité.
 On utilisera comme loi d'échantillonnage une loi exponentielle translatée de 3, de paramètre $\lambda$ notée $Y\sim t\mathcal{E}(3, \lambda)$, i.e., la variable aléatoire $Y$ telle que $Y - 3 \sim \mathcal{E}(\lambda)$
 Calculer les poids d'importance associés, et proposer un estimateur de $p^*$
 
\begin{Correction}

On se donne un échantillon $Y_1,\dots, Y_M$ i.i.d. de loi $t\mathcal{E}(3, \lambda)$.
On note $f$ la densité d'une loi normale $\mathcal{N}(0, 1)$ et $g$ la densité d'une loi
 $\mathcal{E}(\lambda)$. On a:
 $$g(y) = \lambda \text{e}^{-\lambda (y - 3)}\mathbf{1}_{y > 3}$$
Pour $1\leq k \leq M$, les poids d'importance sont donnés par
$$W(Y_k) = \frac{f(Y_k)}{g(Y_k)} = \frac{1}{\lambda\sqrt{2\pi}}\text{e}^{-\frac{Y_k^2}{2} + \lambda(Y_k - 3)}$$

Un estimateur de $p^*$ est donc donné par:

$$\hat{p}_M^{IS} = \frac{1}{M}\sum_{k = 1}^M \frac{f(Y_k)}{g(Y_k)} \mathbf{1}_{Y_k > 3}$$
où les $Y_1,\dots, Y_M$ sont des variables aléatoires i.i.d. selon une distribution exponentielle translatée de 3.
 
\end{Correction}
 
 4. Ecrire la variance de l'estimateur comme fonction de $\lambda$. Comment doit on choisir $\lambda$? 
 
\begin{Correction}

 $$\mathbb{V}[\hat{p}_M^{IS}] = \frac{1}{M} \left(\mathbb{E}[W(Y)^2 \mathbf{1}_{Y>3}] - (p^*)^2\right)$$
 Donc, la variance est minimale quand $\mathbb{E}[W(Y)^2]$ est minimal.
\begin{align*}
\mathbb{E}[W(Y)^2] &= \int_{3}^\infty \left(\frac{1}{\lambda\sqrt{2\pi}}\text{e}^{-\frac{x^2}{2} + \lambda(x - 3)}\right)^2 \lambda \text{e}^{-\lambda (x - 3)}\text{d} x&\\
&= \frac{1}{\lambda 2\pi}\text{e}^{-3\lambda}\int_{3}^\infty \text{e}^{-x^2 +\lambda x}&\\
&= \frac{1}{\lambda\sqrt{2\pi}}\text{e}^{-3\lambda}\int_{3}^\infty \frac{1}{\sqrt{2\pi}} \text{e}^{-(x - \frac{\lambda}{2})^2 + \frac{\lambda^2}{4}} & \text{ On fait apparaitre la loi normale}\\
&= \frac{1}{\sqrt{2}\lambda\sqrt{2\pi}}\text{e}^{\frac{\lambda^2}{4} - 3\lambda} \int_{3}^\infty \frac{\sqrt{2}}{\sqrt{2\pi}} \text{e}^{-\frac{(x - \frac{\lambda}{2})^2}{2\times\frac{1}{2}}}\\
&= \frac{1}{2\lambda\sqrt{\pi}}\text{e}^{\frac{\lambda^2}{4} - 3\lambda}(1 - \phi_{\lambda/2,1/2}(3))
\end{align*}
où $\phi_{\lambda/2,1/2}$ est la fonction de répartition d'une loi $\mathcal{N}(\lambda/2, 1/2)$.
 
Ainsi, il faut choisir $\lambda$ qui minimise cette expression.

En `R`, on peut ainsi coder une fonction pour la variance en fonction de $\lambda$:

\end{Correction}

```{r get_IS_variance}
get_IS_variance <- function(lambda, threshold = 3){
  # Note that we add the true -p^2 term, which is not important 
  # as it is a constant
  0.5 * exp(0.25 * lambda^2 - threshold * lambda) / (lambda * sqrt(pi)) *
    (1 - pnorm(threshold, 0.5 * lambda, sqrt(0.5))) -
    (1 - pnorm(threshold))^2 # p^2
}
```

\begin{Correction} 
 On peut représenter la courbe graphiquement:
\end{Correction} 
 
```{r plot_lambda}
tibble(lambda = seq(0.01, 10, by = 0.01)) %>% # initial lambda
  mutate(variance = get_IS_variance(lambda)) %>% # Related variance
  ggplot(mapping = aes(x = lambda, y = variance)) + # then plot it
  geom_line() + 
  labs(x = expression(lambda), y = "Variance de l'estimateur")
```
 
 \begin{Correction}
 On peut montrer par optimisation numérique que cette valeur optimale est légèrement supérieure à $\lambda = 3.5$. La variance est de l'ordre de $7^10^{-9}$.
\end{Correction}

```{r optimize_variance}
# Numerical optimization in R
optimize(f = get_IS_variance, interval = c(0.01, 10))
```
 
 \begin{Correction}
 On a énormémement gagné par rapport à l'estimateur Monte Carlo où la variance
était de l'ordre de $10^{-3}$!
\end{Correction}
 
5. Donner un estimateur empirique de cette variance, et donner l'expression de l'intervalle de confiance à 95% pour l'estimateur de $p^*$.

\begin{Correction}
Avec les mêmes notations que pour $\hat{p}^{IS}$, un estimateur empirique de la variance est donné par:

$$\hat{\sigma}^2_{M, IS} = \frac{1}{M}\sum_{k = 1}^M\left(\frac{f(Y_k)}{g(Y_k)} \mathbf{1}_{Y_k > 3} - \hat{p}_M^{IS}\right)^2$$

Un intervalle de confiance asymptotique de niveau 95% est donc donné par:
$$\left[\hat{p}_M^{IS} - 1.96 \sqrt{\frac{\hat{\sigma}^2_{M, IS}}{M}},
\hat{p}_M^{IS} + 1.96 \sqrt{\frac{\hat{\sigma}^2_{M, IS}}{M}}\right]$$
\end{Correction}
 
 6. Implémenter cet estimateur sur `R` avec $\lambda = 3.5$ et le comparer à celui de Monte Carlo.
 
\begin{Correction}

Le squelette de la fonction est le même que celui d'un estimateur de Monte Carlo usuel. Il faut faire attention à bien simuler les échantillons selon la nouvelle loi et à calculer les poids en conséquence.

\end{Correction}
 
```{r get_IS_estimate}
get_IS_estimate <- function(M, lambda, threshold = 3){
  y_sample <- threshold + rexp(M, lambda) # Simulation Y
  above_threshold <-  y_sample > threshold
  z_975 <- qnorm(0.975) # Quantile de la loi normale
  weights <- dnorm(y_sample, 0, 1) / dexp(y_sample - threshold, lambda)
  p_hat <- cumsum(above_threshold * weights) / (1:M)
  sigma2_p_hat = cumsum((above_threshold * weights)^2) / (1:M) - p_hat^2
  tibble(index = 1:M,
         phi_x = above_threshold,
         p_hat = p_hat) %>% 
    mutate(sup_IC_emp = p_hat + z_975 * sqrt(sigma2_p_hat / index), # IC bounds
           inf_IC_emp = p_hat - z_975 * sqrt(sigma2_p_hat / index))
}
```

```{r my_IS_estimate}
my_IS_estimate <- get_IS_estimate(1e4, lambda = 3.5)
```

\begin{Correction}

On peut comparer l'estimation avec la précédente. 
On aggrège les deux tableaux (en rajoutant une colonne Estimateur).
Vous remarquerez la différence dans les échelles!

\end{Correction}

```{r compare_MC_IS}
bind_rows(mutate(my_monte_carlo_estimate,
                 Estimateur = "MC"),
          mutate(my_IS_estimate,
                 Estimateur = "IS")) %>% 
  ggplot(aes(x = index, y = p_hat)) +
    geom_ribbon(mapping = aes(ymin = inf_IC_emp, ymax = sup_IC_emp,
                              fill = Estimateur), 
                alpha = 0.5) +
  geom_line(aes(color = Estimateur)) +
  labs(x = "Effort Monte Carlo",  y = expression(hat(p)),
       title = "Estimation") +
  facet_wrap(.~Estimateur, scales = "free_y") +
  geom_hline(yintercept = 1 - pnorm(3), # True value
             linetype = 2, col = "red") +
  theme(legend.position = "none")
```

 
# Cas problématique

## Premier cas jouet

Afin de montrer qu'un mauvais choix de loi d'échantillonnage peut augmenter drastiquement la variance de l'estimateur, on peut prendre un exemple très simple.

Supposons qu'on veuille estimer par méthode de Monte Carlo $\mathbb{E}[X]$ où $X \sim \mathcal{N}(0, 1)$. 
On se propose de le faire par méthode de Monte Carlo standard et par échantillonnage préférentiel en tirant dans une loi $Y \sim\mathcal{N}(\mu, 1)$ où $\mu$ est choisi par l'utilisateur.

1. Quelle est la variance de l'estimateur de Monte Carlo standard?

\begin{Correction}

Pour un Monte Carlo classique, on simule $X_1,\dots X_M$ i.i.d. de loi $X \sim \mathcal{N}(0, 1)$ et on prend la moyenne empirique. La variance de cet estimateur est $\frac{1}{M}$.

\end{Correction}

2. Quelle est la variance de l'estimateur par échantillonnage préférentiel?

\begin{Correction}

Un simple calcul montre que cette variance est de $\frac{\text{e}^{\mu^2}}{M}$!

\end{Correction}

## Encore pire!

Soit $X$ une variable aléatoire de densité $f_X(x) = 3x^{-4}\mathbf{1}_{x\geq 1}$ (on dit que $X$ suit une loi de Pareto de paramètres (1, 3)).

1. Calculer $p = \mathbb{P}(X>10)$

\begin{Correction}
$$\mathbb{P}(X>10) = \int_{10}^{\infty}3x^{-4}\mathbf{1}_{x\geq 1} \text{d} x = \frac{1}{10^{3}}$$
\end{Correction}

2. Supposons qu'on veuille estimer $p$ par méthode de Monte Carlo. Ecrire un estimateur de Monte Carlo standard utilisant un échantillon d'une loi de Pareto.

\begin{Correction}
Soit $X_1,\dots, X_n$ un échantillon de variables aléatoires i.i.d., de loi de Pareto de paramètre 1 et 3, pour approcher $p$, on propose l'estimateur:

$$\hat{p}^{MC}_M = \frac{1}{M}\sum_{k = 1}^M \mathbf{1}_{X_k > 10}$$
\end{Correction}

3. Représenter graphiquement les performances empiriques de cet estimateur pour un effot Monte Carlo de $M= 10^4$. On utilisera la fonction `rpareto` du package `EnvStats`.

\begin{Correction}
On conserve le squelette habituel.
\end{Correction}

```{r get_MC_estimate_pareto}
get_MC_estimate_pareto <- function(M, threshold = 10){
  x_sample <- EnvStats::rpareto(M, 1, 3) # Simulation des X
  above_threshold <-  x_sample > threshold
  z_975 <- qnorm(0.975) # Quantile de la loi normale
  p_hat <- cumsum(above_threshold) / (1:M) # Estimation de p
  # Fast way to compute E[f(x)^2] - E[f(x)]^2 on the fly
  sigma2_p_hat <- cumsum(above_threshold^2) / (1:M) - p_hat^2
  # Sotcking in a data_frame
  tibble(index = 1:M,
         phi_x = above_threshold,
         p_hat = p_hat) %>% 
    mutate(sup_IC_emp = p_hat + z_975 * sqrt(sigma2_p_hat / index), # IC bounds
           inf_IC_emp = p_hat - z_975 * sqrt(sigma2_p_hat / index))
}
```

```{r my_MC_estimate_pareto, cache = T}
set.seed(123) # For reproductible results
my_MC_estimate_pareto <- get_MC_estimate_pareto(5e4)
```

```{r plot_my_MC_estimate_pareto}
my_MC_estimate_pareto %>%
  ggplot(aes(x = index, y = p_hat)) +
    geom_ribbon(mapping = aes(ymin = inf_IC_emp, ymax = sup_IC_emp), 
                fill = "lightblue", alpha = 0.5) +
  geom_point() +
  labs(x = "Effort Monte Carlo",  y = expression(hat(p)),
       title = "Estimation par Monte Carlo") +
  geom_hline(yintercept = 1 - EnvStats::ppareto(10, 1, 3), # True value
             linetype = 2, col = "red")
```

\begin{Correction}
L'estimateur est relativement instable
\end{Correction}

4. On propose maintenant un estimateur par échantillonnage préférentiel comme dans l'exercice précédent.
On choisit comme densité d'échantillonnage celle d'une loi exponentielle translatée de 10, de paramètre $\lambda = 1$. Donnez l'estimateur associé et mettez le en place sous R. Que constatez vous? Comment l'expliquez vous. *Vous pourrez coder vous même la densité d'une loi de Pareto, ou utiliser la fonction* `dpareto` *du package* `EnvStats`.

\begin{Correction}

On note $g$ la densité d'une loi exponentielle de paramètre $\lambda = 1$, translatée de 10.

L'estimateur d'échantillonnage préférentiel est donc:
$$\hat{p}^{IS}_n = \frac{1}{M}\sum_{k = 1}^M \frac{f_X(Y_k)}{g(Y_k)}$$
où $Y_1,\dots, Y_M$ est un échantillon i.i.d. de variables aléatoires de loi exponentielle translatée de 10.

Le squelette de la fonction est strictement identique à celui de l'exercice précédent

\end{Correction}

```{r get_IS_estimate_pareto}
get_IS_estimate_pareto <- function(M, lambda, threshold = 10){
  y_sample <- threshold + rexp(M, rate = lambda) # Simulation Y
  above_threshold <-  y_sample > threshold
  z_975 <- qnorm(0.975) # Quantile de la loi normale
  weights <- EnvStats::dpareto(y_sample, 1, 3) / dexp(y_sample - threshold, lambda)
  p_hat <- cumsum(above_threshold * weights) / (1:M)
  sigma2_p_hat = cumsum((above_threshold * weights)^2) / (1:M) - p_hat^2
  tibble(index = 1:M,
         phi_x = above_threshold,
         p_hat = p_hat) %>% 
    mutate(sup_IC_emp = p_hat + z_975 * sqrt(sigma2_p_hat / index), # IC bounds
           inf_IC_emp = p_hat - z_975 * sqrt(sigma2_p_hat / index))
}
```

```{r my_IS_estimate_pareto}
set.seed(1)
my_IS_estimate_pareto <- get_IS_estimate_pareto(5e4, lambda = 1)
```

```{r plot_my_IS_estimate_pareto}
my_IS_estimate_pareto %>%
  ggplot(aes(x = index, y = p_hat)) +
    geom_ribbon(mapping = aes(ymin = inf_IC_emp, ymax = sup_IC_emp), 
                fill = "lightblue", alpha = 0.5) +
  geom_point() +
  labs(x = "Effort Monte Carlo",  y = expression(hat(p)),
       title = "Estimation par Monte Carlo")  +
  geom_hline(yintercept = 1 - EnvStats::ppareto(10, 1, 3), # True value
             linetype = 2, col = "red")
```

\begin{Correction}

L'estimateur est encore plus instable! La variance ne semble pas nécessairement décroitre avec $M$.

\end{Correction}

5. Que pouvez vous dire de la variance de cet estimateur? 

\begin{Correction}

Regardons la variance de $\hat{p}^{IS}_1$
\begin{align*}
\mathbb{V}[\hat{p}^{IS}_1] &= \mathbb{E}[(\hat{p}^{IS}_1)^2] - p^2\\
&= \mathbb{E}[(\frac{f_X(Y)^2}{g(Y)^2}] - p^2\\
&= \int_{10}^{\infty} \frac{f_X(z)^2}{g(z)^2}g(z)\text{d}z - p^2\\
&= \int_{10}^{\infty} 9z^{-8}\text{e}^{z - 10}\text{d} z - p^2
\end{align*}
La variance est donc infinie!
Notre estimateur est donc sans biais, mais de variance infinie (entre autres conséquences, le TCL ne s'applique pas).

\end{Correction}
 
<!-- # Marche aléatoire du joueur optimiste -->

<!-- Le problème suivant peut être vu par le prisme d'un joueur dans un jeu à espérance négative, qui décide *a priori* de s'arrêter, soit quand il est ruiné, soit quand ses gains ont dépassé le jackpot. -->

<!-- Soit $X_0 = 0$ et $(X_n)_{n\geq 1}$ une suite de variables aléatoires i.i.d. de loi  -->
<!-- $\mathcal{N}(-\mu, 1)$ où $\mu$ est une constante strictement positive (gain pour une partie).  -->
<!-- On note $S_n = \sum_{0}^n X_n$ (somme des gains jusqu'à l'instant $n$). -->
<!-- On se donne un réel $r < 0$ (représentant la ruine) et un réel $j > 0$ (représentant le jackpot).  -->
<!-- On considère le temps d'arrêt $T = \min\left\lbrace n, S_n \leq r \text{ ou } S_n \geq j\right\rbrace$. -->
<!-- On souhaite estimer la probabilité de sortir vainqueur, soit $p^* = \mathbb{P}(S_T \geq j)$. -->

<!-- 1. Proposer un algortihme de simulation de pour une trajectoire $(S_n)_{1\leq n \leq T}$. -->

<!-- \begin{Correction} -->

<!-- \begin{itemize} -->
<!-- \item On part de $S_0 = 0$ -->
<!-- \item Tant que $r < S_t < j$, on tire $S_{t + 1} \sim \mathcal{N}(S_t - \mu, 1)$   -->
<!-- \end{itemize} -->

<!-- \end{Correction} -->

<!-- 2. Pour un effort de Monte Carlo de taille $M$, proposer un estimateur pour $p^*$.  -->

<!-- \begin{Correction} -->

<!-- On tire $M$ trajectoires de la marche aléatoire selon l'algorithme donné plus haut. Pour $1 \leq k \leq M$, on note $S_{T, k}$ la valeur de la trajectoire au temps $T$. -->
<!-- Notre estimateur est alors -->

<!-- $$\hat{p}_M = \frac{1}{M}\sum_{k = 1}^M \mathbf{1}_{S_{T,k} \geq j}$$ -->

<!-- \end{Correction} -->

<!-- 3. Pour $\mu =1, r = -50, j = 5$, implémenter cet estimateur, quelle est la valeur de $\hat{p}^*$ obtenue pour $M = 1000$? Représentez une trajectoire d'une estimation (i.e., la valeur de l'estimation en fonction de $M$)? -->

<!-- ```{r simulate_one_final_point} -->
<!-- simulate_one_final_point <- function(moyenne, r = -50, j = 5){ -->
<!--   s0 <- 0 -->
<!--   stop_condition <- FALSE -->
<!--   while(!stop_condition){ -->
<!--     s0 <- s0 + rnorm(1, moyenne, 1) -->
<!--     stop_condition <- (s0 <= r | s0 >= j) -->
<!--   } -->
<!--   s0 -->
<!-- } -->
<!-- ``` -->

<!-- ```{r get_MC_estimate_random_walk} -->
<!-- get_MC_estimate_random_walk <- function(M, mu = 1, r = -50, j = 5){ -->
<!--   sT_sample <- rerun(M, -->
<!--                     simulate_one_final_point(-mu, r, j)) %>%  -->
<!--     unlist()# Simulation des points finaux -->
<!--   got_jackpot <-  sT_sample >= j -->
<!--   z_975 <- qnorm(0.975) # Quantile de la loi normale -->
<!--   p_hat <- cumsum(got_jackpot) / (1:M) # Estimation de p -->
<!--   # Fast way to compute E[f(x)^2] - E[f(x)]^2 on the fly -->
<!--   sigma2_p_hat <- cumsum(got_jackpot^2) / (1:M) - p_hat^2 -->
<!--   # Sotcking in a data_frame -->
<!--   tibble(index = 1:M, -->
<!--          phi_x = got_jackpot, -->
<!--          p_hat = p_hat) %>%  -->
<!--     mutate(sup_IC_emp = p_hat + z_975 * sqrt(sigma2_p_hat / index), # IC bounds -->
<!--            inf_IC_emp = p_hat - z_975 * sqrt(sigma2_p_hat / index)) -->
<!-- } -->
<!-- ``` -->

<!-- ```{r my_MC_estimate_rw, cache = T} -->
<!-- set.seed(123) # For reproductible results -->
<!-- my_MC_estimate_random_walk <- get_MC_estimate_random_walk(1e3, mu = 1) -->
<!-- ``` -->

<!-- ```{r plot_my_MC_estimate_random_walk} -->
<!-- my_MC_estimate_random_walk %>% -->
<!--   ggplot(aes(x = index, y = p_hat)) + -->
<!--     geom_ribbon(mapping = aes(ymin = inf_IC_emp, ymax = sup_IC_emp),  -->
<!--                 fill = "lightblue", alpha = 0.5) + -->
<!--   geom_point() + -->
<!--   labs(x = "Effort Monte Carlo",  y = expression(hat(p)), -->
<!--        title = "Estimation par Monte Carlo") -->
<!-- ``` -->

<!-- \begin{Correction} -->

<!-- On ne décolle jamais de 0! -->

<!-- \end{Correction} -->

<!-- 4. Pour une séquence observée $s_1, \dots, s_T$ simulée grâce à la méthode de Monte Carlo ci dessus, donner la densité de l'échantillon, notée -->
<!-- $f(s_{1:T})$. -->

<!-- \begin{Correction} -->

<!-- $$f(s_{1:T}) = \frac{1}{\sqrt{2\pi}^n}\prod_{t = 1}^T \text{e}^{-\frac{1}{2}\left(s_t - s_{t-1} + \mu\right)^2}$$ -->

<!-- \end{Correction} -->

<!-- 5. On considère maintenant la marche aléatoire où les $X_n$ sont tirés selon la loi $\mathcal{N}(\mu, 1)$ (n a toujours $X_0 = 0$ et $S_n = \sum_{0}^n X_n$). -->
<!-- Pour une séquence $s_1, \dots, s_T$ simulée ainsi on note $g(s_1, \dots, s_T)$, la densité de l'échantillon, écrire le rapport $\frac{f(s_{1:T})}{g(s_{1:T})}$.  -->

<!-- \begin{Correction} -->

<!-- Le rapport s'écrit seulement: -->

<!-- $$\frac{f(s_{1:T})}{g(s_{1:T})} =  \text{e}^{-2\mu\sum_{t = 1}^T\left(s_t - s_{t-1}\right)} =  \text{e}^{-2\mu s_T} $$ -->

<!-- On notera que ce rapport ne dépend que du point final! -->

<!-- \end{Correction} -->

<!-- 6. Proposer un estimateur par échantillonnage préférentiel pour estimer $p^*$, basé sur la simulation selon la densité $g$. L'estimateur sera noté $\hat{p}_M^{IS}$. De cet estimateur, vous déduirez que $p^* \leq \text{e}^{-2\mu j}$. -->

<!-- \begin{Correction} -->

<!-- Pour $1\leq k \leq M$, on note $\tilde{S}_{T,k}$ le point final de la marche aléatoire obtenue en simulant avec des incréments de loi $\mathcal{N}(\mu, 1)$. -->

<!-- L'estimateur par échantillonnage préférentiel est alors: -->

<!-- $$\hat{p}^{IS}_M = \frac{1}{M}\sum_{k = 1}^M \text{e}^{-2\mu \tilde{S}_{T,k}} \mathbf{1}_{\tilde{S}_{T,k} \geq j}$$ -->

<!-- On en déduit directement que $\hat{p}^{IS}_M \leq \text{e}^{-2\mu j}$, et donc que $\hat{p}^* = \mathbb{E}\left[\hat{p}^{IS}_M\right] \leq \text{e}^{-2\mu j}$ -->

<!-- \end{Correction} -->

<!-- 7. Implémenter cet algorithme, tracez la valeur de l'estimation ainsi que son intervalle de confiance en fonction de $M$. -->

<!-- ```{r get_ratio_final_point} -->
<!-- get_ratio_final_point <- function(final_point, mu){ -->
<!--   exp(-2 * mu * final_point) -->
<!-- } -->
<!-- ``` -->


<!-- ```{r get_IS_estimate_rw} -->
<!-- get_IS_estimate_random_walk <- function(M, mu = 1, r = -50, j = 5){ -->
<!--   sT_sample <- rerun(M, -->
<!--                     simulate_one_final_point(mu, r, j)) %>%  -->
<!--     unlist()# Simulation des points finaux -->
<!--   got_jackpot <-  sT_sample >= j -->
<!--   weights <- get_ratio_final_point(sT_sample, mu) -->
<!--   p_hat <- cumsum(got_jackpot * weights) / (1:M) -->
<!--   sigma2_p_hat = cumsum((got_jackpot * weights)^2) / (1:M) - p_hat^2 -->
<!--   z_975 <- qnorm(0.975) -->
<!--   tibble(index = 1:M, -->
<!--          phi_x = got_jackpot, -->
<!--          p_hat = p_hat) %>%  -->
<!--     mutate(sup_IC_emp = p_hat + z_975 * sqrt(sigma2_p_hat / index), # IC bounds -->
<!--            inf_IC_emp = p_hat - z_975 * sqrt(sigma2_p_hat / index)) -->
<!-- } -->
<!-- ``` -->

<!-- ```{r my_IS_estimate_random_walk} -->
<!-- set.seed(1) -->
<!-- my_IS_estimate_random_walk <- get_IS_estimate_random_walk(1e3, mu = 1) -->
<!-- ``` -->

<!-- ```{r plot_my_IS_estimate_random_walk} -->
<!-- my_IS_estimate_random_walk %>% -->
<!--   ggplot(aes(x = index, y = p_hat)) + -->
<!--     geom_ribbon(mapping = aes(ymin = inf_IC_emp, ymax = sup_IC_emp),  -->
<!--                 fill = "lightblue", alpha = 0.5) + -->
<!--   geom_point() + -->
<!--   labs(x = "Effort Monte Carlo",  y = expression(hat(p)), -->
<!--        title = "Estimation par Monte Carlo") -->
<!-- ``` -->

